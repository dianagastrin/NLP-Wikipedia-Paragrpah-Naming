{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "X = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "all_tokens = set()\n",
    "biography_tokens = list()\n",
    "biography_sentences = list()\n",
    "biography_sentences_tokens = list();\n",
    "\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(file, 'r') as f:\n",
    "            raw_biography_text = f.read()\n",
    "            tokens = word_tokenize(raw_biography_text)\n",
    "            sentences = sent_tokenize(raw_biography_text)\n",
    "            biography_tokens.append(tokens)\n",
    "            all_tokens |= set(tokens)\n",
    "            \n",
    "            biography_sentences.append(sentences)\n",
    "            biography_sentences_tokens.append(list(word_tokenize(sentence) for sentence in sentences))\n",
    "            \n",
    "all_tokens_list = list(all_tokens)\n",
    "number_of_biographies = len(biography_tokens)\n",
    "number_of_tokens = len(all_tokens_list)\n",
    "biography_bow = np.zeros([number_of_biographies, number_of_tokens], dtype = np.int)\n",
    "\n",
    "for i in range(number_of_biographies):\n",
    "    for j in range(len(biography_tokens[i])):\n",
    "        biography_bow[i][all_tokens_list.index(biography_tokens[i][j])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = all_tokens_list\n",
    "biography_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7f6f717909b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 30\n",
    "\n",
    "model = lda.LDA(n_topics=number_of_topics, n_iter=1500, random_state=1)\n",
    "model.fit(biography_bow)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Presley show Parker rock record blues Phillips Sun $ only... (7125)\n",
      "Topic 1: Carrey vaccination Dumb 1994 Dumber law 1995 stated Christmas McCarthy... (7125)\n",
      "Topic 2: you hit As now singing By 1967 able before Award... (7125)\n",
      "Topic 3: ? recorded recalled Love Sullivan broadcast called charts Allen 'd... (7125)\n",
      "Topic 4: [ ] in and ) ( 's which at is... (7125)\n",
      "Topic 5: Elvis Memphis country gospel session Moore sang something films Las... (7125)\n",
      "Topic 6: research ; became Poland scientific 18 daughter 1898 conducted Pasteur... (7125)\n",
      "Topic 7: performance pop popular do All audience Nashville 1976 King artist... (7125)\n",
      "Topic 8: her she [ ] Curie She Pierre Paris Marie radium... (7125)\n",
      "Topic 9: performances Do drug deal ! well lead performing professional magazine... (7125)\n",
      "Topic 10: number studio one RCA shows Vegas sound played chart black... (7125)\n",
      "Topic 11: to the had from first were it an would be... (7125)\n",
      "Topic 12: Armstrong the his mission Moon flew pilot Gemini surface NASA... (7125)\n",
      "Topic 13: Lennon Ono John band McCartney Beatles album song Paul 1969... (7125)\n",
      "Topic 14: Maria French 21 Institute uranium Prize 11 1911 Becquerel Nobel... (7125)\n",
      "Topic 15: he He His August said January three wrote October about... (7125)\n",
      "Topic 16: down people me top over U.S. final came reached 22... (7125)\n",
      "Topic 17: Damon an Best played Harvard Good Bourne Affleck character nb... (7125)\n",
      "Topic 18: music songs album singer became guitar concert albums sessions 1973... (7125)\n",
      "Topic 19: 11 20 8 while attended 9 1962 if man 6... (7125)\n",
      "Topic 20: . of a ] [ in to for that as... (7125)\n",
      "Topic 21: The film has role appeared Actor Golden 2013 Award good... (7125)\n",
      "Topic 22: so up right some To President around Thompson Following test... (7125)\n",
      "Topic 23: 10 University work 13 46 23 did 26 42 52... (7125)\n",
      "Topic 24: group weeks she knew 1968 do saying roll backup return... (7125)\n",
      "Topic 25: `` his '' 's I him ... ' n't all... (7125)\n",
      "Topic 26: , the and was on In not but who time... (7125)\n",
      "Topic 27: Apollo Aldrin lunar flight crew Air LM X-15 Scott astronaut... (7125)\n",
      "Topic 28: York often with saw US felt same revealed With track... (7125)\n",
      "Topic 29: landing Edwards served Eagle ground aircraft seconds planned degree fly... (7125)\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "\n",
    "topics_words = list()\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    # topic_words: words sorted by relevance to topic in descending order\n",
    "    topic_words = list(np.array(vocab)[np.argsort(topic_dist)[::-1]])#[:10]#[:-(n_top_words+1):-1]\n",
    "    #print(topic_words)\n",
    "    topics_words.append(topic_words)\n",
    "    print('Topic {}: {} ({})'.format(i, ' '.join(topic_words[:10])+'...',len(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_word_topic_id(word, topics_words):\n",
    "    topic_id = -1\n",
    "    min_topic_index = number_of_tokens + 1\n",
    "    for current_topic_id in range(number_of_topics):\n",
    "        index = topics_words[current_topic_id].index(word)\n",
    "        if index < min_topic_index:\n",
    "            topic_id = current_topic_id\n",
    "            min_topic_index = index\n",
    "            \n",
    "    return topic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " calculate_word_topic_id(\"Elvis\", topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_vocabulary_topic_ids(vocabulary, topics_words):\n",
    "    topic_ids = list()\n",
    "    for word in vocab:\n",
    "        topic_ids.append(calculate_word_topic_id(word, topics_words))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_topic_ids = calculate_vocabulary_topic_ids(vocab, topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocabulary_word_topic_id(vocabulary, vocabulary_topic_ids, word):\n",
    "    return vocabulary_topic_ids[vocabulary.index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocabulary_word_topic_id(vocab, vocabulary_topic_ids, \"Elvis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#biography_sentences_tokens\n",
    "\n",
    "def get_sentence_topic_ids(sentence, topics_words):\n",
    "    topic_ids = list()\n",
    "    for word in sentence:\n",
    "        topic_ids.append(get_vocabulary_word_topic_id(vocab, vocabulary_topic_ids, word))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_sentence_topic_ids(biography_sentences_tokens[1][0], topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences_topic_ids(sentences, topic_words):\n",
    "    topic_ids = list()\n",
    "    for sentence in sentences:\n",
    "        topic_ids.append(get_sentence_topic_ids(sentence, topics_words))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_topic_ids = get_sentences_topic_ids(biography_sentences_tokens[0], topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_biography_sentences_topic_ids(biography_sentences_tokens, topic_words):\n",
    "    biography_sentences_topic_ids = list()\n",
    "    for sentences in biography_sentences_tokens:\n",
    "        biography_sentences_topic_ids.append(get_sentences_topic_ids(sentences, topic_words))\n",
    "    \n",
    "    return biography_sentences_topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biography_sentences_topic_ids = get_biography_sentences_topic_ids(biography_sentences_tokens, topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_sentence_topics_frequency(sentence_topic_ids, number_of_topics):\n",
    "    topics_frequencies = np.zeros(number_of_topics)\n",
    "    for topic_id in sentence_topic_ids:\n",
    "        topics_frequencies[topic_id] += 1\n",
    "    \n",
    "    return topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_sentences_topics_frequency(sentences_topic_ids, number_of_topics):\n",
    "    sentences_topics_frequencies = list()\n",
    "    for sentence in sentences_topic_ids:\n",
    "        sentences_topics_frequencies.append(calculate_sentence_topics_frequency(sentence, number_of_topics))\n",
    "        \n",
    "    return sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_biography_sentences_topics_frequencies(biography_sentences_topic_ids, number_of_topics):\n",
    "    biography_sentences_topics_frequencies = list()\n",
    "    for sentences in biography_sentences_topic_ids:\n",
    "        biography_sentences_topics_frequencies.append(calculate_sentences_topics_frequency(sentences, number_of_topics))\n",
    "        \n",
    "    return biography_sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biography_sentences_topics_frequencies = calculate_biography_sentences_topics_frequencies(biography_sentences_topic_ids, number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#biography_sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_coherence_score(sentences_topics_frequencies, number_of_topics, position, window_size):\n",
    "    pre_topics_frequencies = np.zeros(number_of_topics)\n",
    "    for i in range(window_size):\n",
    "        pre_topics_frequencies += sentences_topics_frequencies[position - i]\n",
    "        \n",
    "    post_topics_frequencies = np.zeros(number_of_topics)\n",
    "    for i in range(window_size):\n",
    "        post_topics_frequencies += sentences_topics_frequencies[position + 1 + i]\n",
    "        \n",
    "    dot_product = np.dot(pre_topics_frequencies, post_topics_frequencies)\n",
    "    pre_norm = np.linalg.norm(pre_topics_frequencies)\n",
    "    post_norm = np.linalg.norm(post_topics_frequencies)\n",
    "    \n",
    "    cosine_similarity = dot_product / (pre_norm * post_norm)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82138298287197387"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_coherence_score(biography_sentences_topics_frequencies[0], number_of_topics, 65, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_coherence_scores(sentences_topics_frequencies, number_of_topics, window_size):\n",
    "    coherence_scores = list()\n",
    "    for i in range(len(sentences_topics_frequencies) - 2 * window_size):\n",
    "        score = calculate_coherence_score(sentences_topics_frequencies, number_of_topics, window_size + i - 1, window_size)\n",
    "        coherence_scores.append(score)\n",
    "        \n",
    "    return coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_depth_scores(coherence_scores):\n",
    "    depth_scores = list()\n",
    "    for i in range(len(coherence_scores)):\n",
    "        hl = coherence_scores[i]\n",
    "        hr = coherence_scores[i]\n",
    "        for j in range(i):\n",
    "            if coherence_scores[j] > coherence_scores[i]:\n",
    "                hl = coherence_scores[j]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for j in range(i + 1, len(coherence_scores)):\n",
    "            if coherence_scores[j] > coherence_scores[i]:\n",
    "                hr = coherence_scores[j]\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        depth_score = 0.5 * (hl + hr - 2 * coherence_scores[i])\n",
    "        depth_scores.append(depth_score)\n",
    "        \n",
    "    return depth_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coherence_scores = calculate_coherence_scores(biography_sentences_topics_frequencies[0], number_of_topics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_scores = calculate_depth_scores(coherence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.mean(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = np.std(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00054664782276359937"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean - std /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#depth_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biography_sentences_topics_frequencies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neil Alden Armstrong (August 5, 1930 – August 25, 2012) was an American astronaut and the first person to walk on the Moon.',\n",
       " 'He was also an aerospace engineer, naval aviator, test pilot, and university professor.',\n",
       " 'Before becoming an astronaut, Armstrong was an officer in the U.S. Navy and served in the Korean War.',\n",
       " \"After the war, he earned his bachelor's degree at Purdue University and served as a test pilot at the National Advisory Committee for Aeronautics(NACA) High-Speed Flight Station, where he logged over 900 flights.\",\n",
       " 'He later completed graduate studies at theUniversity of Southern California.',\n",
       " \"A participant in the U.S. Air Force's Man in Space Soonest and X-20 Dyna-Soar human spaceflight programs, Armstrong joined the NASA Astronaut Corps in 1962.\",\n",
       " \"He made his first space flight as command pilot of Gemini 8 in March 1966, becoming NASA's first civilian astronaut to fly in space.\",\n",
       " 'He performed the first docking of two spacecraft, with pilot David Scott.',\n",
       " '[1] This mission was aborted after Armstrong used some of his reentry control fuel to prevent a dangerous spin caused by a stuck thruster, in the first in-flight space emergency.',\n",
       " \"Armstrong's second and last spaceflight was as commander of Apollo 11, the first manned Moon landing mission in July 1969.\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biography_sentences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James Eugene \"Jim\" Carrey (/ˈkæri/; born January 17, 1962)[3] is a Canadian American actor, comedian, impressionist, screenwriter, and film producer.',\n",
       " 'He is known for his highly energetic slapstick performances.',\n",
       " '[4]\\nCarrey first gained recognition in 1990 after landing a recurring role in the sketch comedy In Living Color.',\n",
       " 'His first leading roles in major productions came with Ace Ventura: Pet Detective (1994), Dumb and Dumber (1994), The Mask (1994), and Ace Ventura: When Nature Calls (1995), as well as a supporting role in Batman Forever (1995) and a lead role in Liar Liar (1997).',\n",
       " 'He then starred in The Truman Show (1998) and Man on the Moon (1999), with each garnering him a Golden Globe Award for Best Actor.',\n",
       " \"In the 2000s, he gained further recognition for his portrayal of the Grinch in How the Grinch Stole Christmas (2000), as well as Bruce Almighty (2003), Eternal Sunshine of the Spotless Mind (2004), Lemony Snicket's A Series of Unfortunate Events (2004), Fun with Dick and Jane (2005), Yes Man (2008), Horton Hears a Who!\",\n",
       " '(2008) and A Christmas Carol(2009).',\n",
       " \"In the 2010s, he has starred in Mr. Popper's Penguins (2011) and The Incredible Burt Wonderstone (2013).\",\n",
       " 'In 2013, he appeared in Kick-Ass 2 as Colonel Stars and Stripes.',\n",
       " 'Controversially, he retracted support for the film two months prior to its release.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biography_sentences[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6045.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.70306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.17271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           length\n",
       "count  6045.00000\n",
       "mean      9.70306\n",
       "std       8.17271\n",
       "min       0.00000\n",
       "25%       5.00000\n",
       "50%       7.00000\n",
       "75%      12.00000\n",
       "max     102.00000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pickle,pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "bios = pandas.read_pickle('../paragraphs_by_articles.pickle')\n",
    "lengths = pandas.DataFrame([{'length' : len(x)} for x in bios])\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f5f7e3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths.length.plot(bins=100, kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can set the number of divisions for tiling at 25 or so. I guess the number of topics for LDA should be around that ball park too. So we can keep it at 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Duane Ackerson (born 1942) is an American writer of speculative poetry and fiction. He currently lives in Salem, Oregon.\\nDuane Ackerson's work has appeared in anthologies that include The Year's Best SF 1974, 100 Great Science Fiction Short Short Stories, Future Pastimes, and the textbook Writing Poetry. He has won the Rhysling Award for Best Short Poem twice, in 1978 and 1979. The Bird at the End of the Universe\\nThe Eggplant & Other Absurdities\\nWeathering\\nUA Flight to Chicago. Lincoln, Nebraska: The Best Cellar Press, 1971.  Duane Ackerson at the Internet Speculative Fiction Database\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condenced_bios = [\" \".join([part[1] for part in bio]) for bio in bios]\n",
    "condenced_bios[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tokens\n",
      "Percent: [##################################################] 100%\n",
      " creating bow\n",
      "Percent: [##################################################] 100%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 49548)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "def progress(i, end_val, bar_length=50):\n",
    "    percent = float(i) / end_val\n",
    "    hashes = '#' * int(round(percent * bar_length))\n",
    "    spaces = ' ' * (bar_length - len(hashes))\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(hashes + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "all_tokens = set()\n",
    "biography_tokens = list()\n",
    "biography_sentences = list()\n",
    "biography_sentences_tokens = list();\n",
    "print(\"getting tokens\") \n",
    "for ind,bio in enumerate(condenced_bios[:500]):\n",
    "    tokens = word_tokenize(bio)\n",
    "    sentences = sent_tokenize(bio)\n",
    "    biography_tokens.append(tokens)\n",
    "    all_tokens |= set(tokens)\n",
    "    biography_sentences.append(sentences)\n",
    "    biography_sentences_tokens.append(list(word_tokenize(sentence) for sentence in sentences))\n",
    "    progress(ind+1,500)\n",
    "            \n",
    "all_tokens_list = list(all_tokens)\n",
    "number_of_biographies = len(biography_tokens)\n",
    "number_of_tokens = len(all_tokens_list)\n",
    "biography_bow = np.zeros([number_of_biographies, number_of_tokens], dtype = np.int)\n",
    "\n",
    "print(\"\\n\", \"creating bow\")\n",
    "for i in range(number_of_biographies):\n",
    "    for j in range(len(biography_tokens[i])):\n",
    "        biography_bow[i][all_tokens_list.index(biography_tokens[i][j])] += 1\n",
    "    progress(i+1,number_of_biographies)\n",
    "vocab = all_tokens_list\n",
    "biography_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 33s, sys: 156 ms, total: 7min 33s\n",
      "Wall time: 7min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7f6f5c8f9e48>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 30\n",
    "model = lda.LDA(n_topics=number_of_topics, n_iter=1500, random_state=1)\n",
    "%time model.fit(biography_bow)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: , ) ( . of the and in The a...\n",
      "Topic 1: : Cisneros her Carver Fulton she By de `` Raymond...\n",
      "Topic 2: the , . of and to a in as ''...\n",
      "Topic 3: , : Press with Poetry & New poems University Books...\n",
      "Topic 4: : Brodsky – Poems ( Volume Louis Faulkner * =...\n",
      "Topic 5: Adams Emerson Alcott Grimké John Boston May Massachusetts ISBN Waldo...\n",
      "Topic 6: '' , `` of 's The poetry poems : work...\n",
      "Topic 7: , Eliot New Poems York poetry : poet Frost Harvard...\n",
      "Topic 8: . , : by New Edited York The Brennan Fiction...\n",
      "Topic 9: , his was . he in a He to at...\n",
      "Topic 10: . , : Press California San Angeles Black Bukowski Los...\n",
      "Topic 11: New Mexico Angelou state The Indian is Alexie Native %...\n",
      "Topic 12: : Brautigan http Agee de ISBN San Acosta Ghigna Guenther...\n",
      "Topic 13: , the and in of . a is has on...\n",
      "Topic 14: , . : University Poetry Press of the Award for...\n",
      "Topic 15: is AI are human Eiseley be intelligence : ) or...\n",
      "Topic 16: the Buck Allen ! Hall 's for season Cardinals baseball...\n",
      "Topic 17: `` '' Dylan , on 's album and music songs...\n",
      "Topic 18: that is I The it ... be you my his...\n",
      "Topic 19: Crane Crosby Geisel The Stephen Seuss Hart Dr. Press War...\n",
      "Topic 20: '' The `` : 's & Bierce A - 2012...\n",
      "Topic 21: . ISBN '' `` ; ^ : Retrieved The New...\n",
      "Topic 22: , and . was at New in Works York American...\n",
      "Topic 23: , : Paul Auster Press de Davenport Dennis Cooper Paris...\n",
      "Topic 24: the Berry Espada Halleck Andrews State Senate against York President...\n",
      "Topic 25: Carolina North South Brooks Chicago – University Glass Southern Field...\n",
      "Topic 26: Ginsberg Corso Allen Ferlinghetti Beat San Francisco Cohen ISBN Kerouac...\n",
      "Topic 27: ] [ Baraka New : Goodman York film ! Prima...\n",
      "Topic 28: her she She was Her in Dickinson and women poems...\n",
      "Topic 29: . : , York Cummings Black New black African-American African...\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "\n",
    "topics_words = list()\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    # topic_words: words sorted by relevance to topic in descending order\n",
    "    topic_words = list(np.array(vocab)[np.argsort(topic_dist)[::-1]])#[:10]#[:-(n_top_words+1):-1]\n",
    "    #print(topic_words)\n",
    "    topics_words.append(topic_words)\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words[:10])+'...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('topics_500.pkl','wb') as topics:\n",
    "    pickle.dump(topic_word,topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.01458783e-08,   2.41239094e-05,   8.01458783e-08, ...,\n",
       "         8.01458783e-08,   8.01458783e-08,   8.01458783e-08])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pickle.load(open('topics_500.pkl','rb'))\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
