{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "X = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "all_tokens = set()\n",
    "biography_tokens = list()\n",
    "biography_sentences = list()\n",
    "biography_sentences_tokens = list();\n",
    "\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(file, 'r') as f:\n",
    "            raw_biography_text = f.read()\n",
    "            tokens = word_tokenize(raw_biography_text)\n",
    "            sentences = sent_tokenize(raw_biography_text)\n",
    "            biography_tokens.append(tokens)\n",
    "            all_tokens |= set(tokens)\n",
    "            \n",
    "            biography_sentences.append(sentences)\n",
    "            biography_sentences_tokens.append(list(word_tokenize(sentence) for sentence in sentences))\n",
    "            \n",
    "all_tokens_list = list(all_tokens)\n",
    "number_of_biographies = len(biography_tokens)\n",
    "number_of_tokens = len(all_tokens_list)\n",
    "biography_bow = np.zeros([number_of_biographies, number_of_tokens], dtype = np.int)\n",
    "\n",
    "for i in range(number_of_biographies):\n",
    "    for j in range(len(biography_tokens[i])):\n",
    "        biography_bow[i][all_tokens_list.index(biography_tokens[i][j])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7125)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = all_tokens_list\n",
    "biography_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7f6fd342b668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 30\n",
    "\n",
    "model = lda.LDA(n_topics=number_of_topics, n_iter=1500, random_state=1)\n",
    "model.fit(biography_bow)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: top played As me gospel can fans much minutes 104... (7125)\n",
      "Topic 1: , the . and of [ to in ] for... (7125)\n",
      "Topic 2: `` his '' 's he I him ' n't all... (7125)\n",
      "Topic 3: country something many so barely Though military described unable contemporary... (7125)\n",
      "Topic 4: ( ) also where father 8 member University 17 School... (7125)\n",
      "Topic 5: Carrey vaccination 1994 2004 Comedy gained 2011 law Dumb Dumber... (7125)\n",
      "Topic 6: Presley Elvis studio Parker show RCA pop stage Sun blues... (7125)\n",
      "Topic 7: ] [ In work 11 26 born 13 53 public... (7125)\n",
      "Topic 8: The 's as film has a role Best appeared is... (7125)\n",
      "Topic 9: Damon in which a played Harvard Good Affleck Academy Bourne... (7125)\n",
      "Topic 10: he He three such next received American As 3 too... (7125)\n",
      "Topic 11: songs singer rock popular just soundtrack December There broadcast charts... (7125)\n",
      "Topic 12: John ... Paul York when solo mother magazine Peace other... (7125)\n",
      "Topic 13: a was had by were it not but with be... (7125)\n",
      "Topic 14: almost group knew 1960 way successful 1971 weeks back outside... (7125)\n",
      "Topic 15: shows Phillips Vegas sound number Sullivan said Christmas Blue Las... (7125)\n",
      "Topic 16: Aldrin lunar mission 11 engine space km astronaut control Eagle... (7125)\n",
      "Topic 17: It audience $ Love chart into response down local both... (7125)\n",
      "Topic 18: ; both off working earlier training person return President degree... (7125)\n",
      "Topic 19: album music recorded single often we film ? do January... (7125)\n",
      "Topic 20: Lennon Ono band McCartney Beatles song which 1969 1980 US... (7125)\n",
      "Topic 21: said 16 if several 30 called 100 George hours where... (7125)\n",
      "Topic 22: only did second them 1 other months tour again four... (7125)\n",
      "Topic 23: Armstrong the landing Apollo Moon flight flew crew Gemini Edwards... (7125)\n",
      "Topic 24: 10 21 Prize woman uranium Curies research 28 Bronis≈Çawa husband... (7125)\n",
      "Topic 25: Memphis record Moore people Me Graceland recordings King trio Black... (7125)\n",
      "Topic 26: recalled albums concert you contract singing special 1976 York sessions... (7125)\n",
      "Topic 27: pilot for surface NASA feet X-15 Force spacecraft down astronauts... (7125)\n",
      "Topic 28: her she Curie She Pierre Paris Marie Maria radium Nobel... (7125)\n",
      "Topic 29: would first they this than have could before 20 there... (7125)\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "\n",
    "topics_words = list()\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    # topic_words: words sorted by relevance to topic in descending order\n",
    "    topic_words = list(np.array(vocab)[np.argsort(topic_dist)[::-1]])#[:10]#[:-(n_top_words+1):-1]\n",
    "    #print(topic_words)\n",
    "    topics_words.append(topic_words)\n",
    "    print('Topic {}: {} ({})'.format(i, ' '.join(topic_words[:10])+'...',len(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_word_topic_id(word, topics_words):\n",
    "    topic_id = -1\n",
    "    min_topic_index = number_of_tokens + 1\n",
    "    for current_topic_id in range(number_of_topics):\n",
    "        index = topics_words[current_topic_id].index(word)\n",
    "        if index < min_topic_index:\n",
    "            topic_id = current_topic_id\n",
    "            min_topic_index = index\n",
    "            \n",
    "    return topic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " calculate_word_topic_id(\"Elvis\", topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_vocabulary_topic_ids(vocabulary, topics_words):\n",
    "    topic_ids = list()\n",
    "    for word in vocab:\n",
    "        topic_ids.append(calculate_word_topic_id(word, topics_words))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_topic_ids = calculate_vocabulary_topic_ids(vocab, topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocabulary_word_topic_id(vocabulary, vocabulary_topic_ids, word):\n",
    "    return vocabulary_topic_ids[vocabulary.index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocabulary_word_topic_id(vocab, vocabulary_topic_ids, \"Elvis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#biography_sentences_tokens\n",
    "\n",
    "def get_sentence_topic_ids(sentence, topics_words):\n",
    "    topic_ids = list()\n",
    "    for word in sentence:\n",
    "        topic_ids.append(get_vocabulary_word_topic_id(vocab, vocabulary_topic_ids, word))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_sentence_topic_ids(biography_sentences_tokens[1][0], topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences_topic_ids(sentences, topic_words):\n",
    "    topic_ids = list()\n",
    "    for sentence in sentences:\n",
    "        topic_ids.append(get_sentence_topic_ids(sentence, topics_words))\n",
    "        \n",
    "    return topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_topic_ids = get_sentences_topic_ids(biography_sentences_tokens[0], topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_biography_sentences_topic_ids(biography_sentences_tokens, topic_words):\n",
    "    biography_sentences_topic_ids = list()\n",
    "    for sentences in biography_sentences_tokens:\n",
    "        biography_sentences_topic_ids.append(get_sentences_topic_ids(sentences, topic_words))\n",
    "    \n",
    "    return biography_sentences_topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biography_sentences_topic_ids = get_biography_sentences_topic_ids(biography_sentences_tokens, topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_sentence_topics_frequency(sentence_topic_ids, number_of_topics):\n",
    "    topics_frequencies = np.zeros(number_of_topics)\n",
    "    for topic_id in sentence_topic_ids:\n",
    "        topics_frequencies[topic_id] += 1\n",
    "    \n",
    "    return topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_sentences_topics_frequency(sentences_topic_ids, number_of_topics):\n",
    "    sentences_topics_frequencies = list()\n",
    "    for sentence in sentences_topic_ids:\n",
    "        sentences_topics_frequencies.append(calculate_sentence_topics_frequency(sentence, number_of_topics))\n",
    "        \n",
    "    return sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_biography_sentences_topics_frequencies(biography_sentences_topic_ids, number_of_topics):\n",
    "    biography_sentences_topics_frequencies = list()\n",
    "    for sentences in biography_sentences_topic_ids:\n",
    "        biography_sentences_topics_frequencies.append(calculate_sentences_topics_frequency(sentences, number_of_topics))\n",
    "        \n",
    "    return biography_sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biography_sentences_topics_frequencies = calculate_biography_sentences_topics_frequencies(biography_sentences_topic_ids, number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#biography_sentences_topics_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_coherence_score(sentences_topics_frequencies, number_of_topics, position, window_size):\n",
    "    pre_topics_frequencies = np.zeros(number_of_topics)\n",
    "    for i in range(window_size):\n",
    "        pre_topics_frequencies += sentences_topics_frequencies[position - i]\n",
    "        \n",
    "    post_topics_frequencies = np.zeros(number_of_topics)\n",
    "    for i in range(window_size):\n",
    "        post_topics_frequencies += sentences_topics_frequencies[position + 1 + i]\n",
    "        \n",
    "    dot_product = np.dot(pre_topics_frequencies, post_topics_frequencies)\n",
    "    pre_norm = np.linalg.norm(pre_topics_frequencies)\n",
    "    post_norm = np.linalg.norm(post_topics_frequencies)\n",
    "    \n",
    "    cosine_similarity = dot_product / (pre_norm * post_norm)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94830423104190387"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_coherence_score(biography_sentences_topics_frequencies[0], number_of_topics, 65, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_coherence_scores(sentences_topics_frequencies, number_of_topics, window_size):\n",
    "    coherence_scores = list()\n",
    "    for i in range(len(sentences_topics_frequencies) - 2 * window_size):\n",
    "        score = calculate_coherence_score(sentences_topics_frequencies, number_of_topics, window_size + i - 1, window_size)\n",
    "        coherence_scores.append(score)\n",
    "        \n",
    "    return coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_depth_scores(coherence_scores):\n",
    "    depth_scores = list()\n",
    "    for i in range(len(coherence_scores)):\n",
    "        hl = coherence_scores[i]\n",
    "        hr = coherence_scores[i]\n",
    "        for j in range(i):\n",
    "            if coherence_scores[j] > coherence_scores[i]:\n",
    "                hl = coherence_scores[j]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for j in range(i + 1, len(coherence_scores)):\n",
    "            if coherence_scores[j] > coherence_scores[i]:\n",
    "                hr = coherence_scores[j]\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        depth_score = 0.5 * (hl + hr - 2 * coherence_scores[i])\n",
    "        depth_scores.append(depth_score)\n",
    "        \n",
    "    return depth_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coherence_scores = calculate_coherence_scores(biography_sentences_topics_frequencies[0], number_of_topics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_scores = calculate_depth_scores(coherence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.mean(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = np.std(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012577220531536145"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean - std /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#depth_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biography_sentences_topics_frequencies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neil Alden Armstrong (August 5, 1930 ‚Äì August 25, 2012) was an American astronaut and the first person to walk on the Moon.',\n",
       " 'He was also an aerospace engineer, naval aviator, test pilot, and university professor.',\n",
       " 'Before becoming an astronaut, Armstrong was an officer in the U.S. Navy and served in the Korean War.',\n",
       " \"After the war, he earned his bachelor's degree at Purdue University and served as a test pilot at the National Advisory Committee for Aeronautics(NACA) High-Speed Flight Station, where he logged over 900 flights.\",\n",
       " 'He later completed graduate studies at theUniversity of Southern California.',\n",
       " \"A participant in the U.S. Air Force's Man in Space Soonest and X-20 Dyna-Soar human spaceflight programs, Armstrong joined the NASA Astronaut Corps in 1962.\",\n",
       " \"He made his first space flight as command pilot of Gemini 8 in March 1966, becoming NASA's first civilian astronaut to fly in space.\",\n",
       " 'He performed the first docking of two spacecraft, with pilot David Scott.',\n",
       " '[1] This mission was aborted after Armstrong used some of his reentry control fuel to prevent a dangerous spin caused by a stuck thruster, in the first in-flight space emergency.',\n",
       " \"Armstrong's second and last spaceflight was as commander of Apollo 11, the first manned Moon landing mission in July 1969.\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biography_sentences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James Eugene \"Jim\" Carrey (/Ààk√¶ri/; born January 17, 1962)[3] is a Canadian American actor, comedian, impressionist, screenwriter, and film producer.',\n",
       " 'He is known for his highly energetic slapstick performances.',\n",
       " '[4]\\nCarrey first gained recognition in 1990 after landing a recurring role in the sketch comedy In Living Color.',\n",
       " 'His first leading roles in major productions came with Ace Ventura: Pet Detective (1994), Dumb and Dumber (1994), The Mask (1994), and Ace Ventura: When Nature Calls (1995), as well as a supporting role in Batman Forever (1995) and a lead role in Liar Liar (1997).',\n",
       " 'He then starred in The Truman Show (1998) and Man on the Moon (1999), with each garnering him a Golden Globe Award for Best Actor.',\n",
       " \"In the 2000s, he gained further recognition for his portrayal of the Grinch in How the Grinch Stole Christmas (2000), as well as Bruce Almighty (2003), Eternal Sunshine of the Spotless Mind (2004), Lemony Snicket's A Series of Unfortunate Events (2004), Fun with Dick and Jane (2005), Yes Man (2008), Horton Hears a Who!\",\n",
       " '(2008) and A Christmas Carol(2009).',\n",
       " \"In the 2010s, he has starred in Mr. Popper's Penguins (2011) and The Incredible Burt Wonderstone (2013).\",\n",
       " 'In 2013, he appeared in Kick-Ass 2 as Colonel Stars and Stripes.',\n",
       " 'Controversially, he retracted support for the film two months prior to its release.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biography_sentences[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
